<!DOCTYPE html>
<!-- saved from url=(0045)https://mbzuai-cl.github.io/2023/programday2/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!--<base href=".">--><base href=".">
    <link rel="shortcut icon" type="image/png" href="https://mbzuai-cl.github.io/2023/assets/favicon.png">
    <link rel="stylesheet" type="text/css" media="all" href="./MLLM2024_day2_files/main.css">
    <meta name="description" content="MBZUAI Machine Learning for Large Models Workshop 2024">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>MBZUAI Workshop on Data, Learning, and Biological Problems</title>
</head>

<body>

    <div class="banner">
        <img src="./MLLM2024_files/banner.jpeg" alt="MBZUAI Machine Learning for Large Models 2024 Banner">
        <div class="top-left">
            <span class="title2">MBZUAI Workshop on </span>
            <br><br> <span class="title1" style="font-size: 38px;">Data, Learning, and Biological Problems</span> 
            <!-- <br><br>
            <span class="year">Empowering Sustainable Futures</span> -->
        </div>
        <div class="bottom-right">
            Nov 10-11, 2025 <br> MBZUAI, Abu Dhabi
        </div>
    </div>

   <table class="navigation">
        <tbody><tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href="index.html">Home</a>
            </td>
            <!-- <td class="navigation">
                <a title="Speakers List" href="speakerlist.html">Speakers List</a> 
            </td> -->
            <td class="navigation">
                <a title="Conference Program" href="day1.html">Program Day 1</a> 
            </td>
            <!-- <td class="navigation">
                <a title="Conference Program" href="https://mbzuai.ac.ae/">MBZUAI</a> 
            </td> -->
            <td class="navigation">
                <a title="Conference Program Day 2" href="day2.html">Program Day 2</a> 
            </td>
        </tr>
    </tbody></table>

    <h2>Day 2 Program (November 11, Tuesday)</h2>
     <table id="Mladen Kolar">
        <tbody><tr>
            <td class="date" rowspan="3">
                9:00am
            </td>
            <td class="title">
                Trans-Glasso: A Transfer Learning Approach to Precision Matrix Estimation
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/mladen-kolar/"><b>Mladen Kolar</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Many real-world systems—ranging from gene regulatory interactions in biology to financial asset dependencies—can be represented by networks, whose edges correspond to conditional relationships among variables. These relationships are succinctly captured by the precision matrix of a multivariate distribution. Estimating the precision matrix is thus fundamental to uncovering the underlying network structure. However, this task can be challenging when the available data for the target domain are limited, undermining accurate inference.

In this talk, I will present Trans-Glasso, a novel two-step transfer learning framework for precision matrix estimation that leverages data from source studies to improve estimates in the target study. First, Trans-Glasso identifies shared and unique features across studies via a multi-task learning objective. Then, it refines these initial estimates through differential network estimation to account for structural differences between the target and source precision matrices. Assuming that most entries of the target precision matrix are shared with at least one source matrix, we derive non-asymptotic error bounds and show that Trans-Glasso achieves minimax optimality under certain conditions.

Through extensive simulations, Trans-Glasso demonstrates improved performance over standard methods, especially in small-sample settings. Applications to gene regulatory networks across multiple brain tissues and protein networks in various cancer subtypes confirm its practical effectiveness in biological contexts, where understanding network structures can provide insights into disease mechanisms and potential interventions. Beyond biology, these techniques are broadly applicable wherever precision matrix estimation and network inference play a crucial role, including neuroscience, finance, and social science.

This is joint work with Boxin Zhao and Cong Ma.

        </td></tr>
    </tbody></table>


    <table id="Samuel Kou">
        <tbody><tr>
            <td class="date" rowspan="3">
             9:30am
            </td>
            <td class="title">
                Generate diverse protein conformations through AlphaFold
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://statistics.fas.harvard.edu/people/samuel-kou"><b>Samuel Kou</b></a> (Harvard)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The introduction of AlphaFold has revolutionized the task of protein structure prediction from a given sequence of amino acids; the groundbreaking contribution of AlphaFold was recognized by the 2024 Nobel Prize in Chemistry. As a deep-learning based method, AlphaFold was trained from the publicly available Protein Data Bank (PDB), a database of known protein structures. An inherent limitation of AlphaFold is that its prediction can only give a static structure, whereas in reality, the structures of proteins are dynamic and can change in response to their environment or binding partners, with significant biological consequences. In this talk, we focus on enhancing and diversifying protein structure prediction using AlphaFold. Through a principled iterative statistical sampling framework, we significantly expand AlphaFold’s capabilities, enabling it to explore a broader conformational space. Key methodologies involve modifying the multiple sequence alignment (MSA) and template inputs to encourage AlphaFold to explore different conformations, thereby increasing structural diversity. This is achieved in particular through an iterative sequential sampling approach, which allows for the incorporation of protein residue co-evolutionary information in the structure prediction, broadening the conformational possibilities that AlphaFold can investigate. We will illustrate the capabilities of the statistical sampling approach through examples.
        </td></tr>
    </tbody></table>


    <table id="Eric Moulines">
        <tbody><tr>
            <td class="date" rowspan="3">
                10:00am
            </td>
            <td class="title">
                Reward-Driven Generation in Denoising Diffusion Models
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/professor-eric-moulines/"><b>Eric Moulines</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                We introduce a general framework for reward-driven generation in denoising diffusion probabilistic models (DDPMs), bridging Bayesian inference and reinforcement learning. The proposed approach formulates controlled generation as sampling from reweighted diffusion priors, where the weighting function encodes likelihood or reward information. We derive diffusion-based approximations of posterior marginals and introduce a mixture-guided Gibbs scheme enabling efficient conditional sampling without retraining. This formulation unifies diffusion posterior sampling and guided generation under a common probabilistic perspective. Applications to linear and nonlinear inverse problems, as well as multimodal tasks such as audio source separation, illustrate the effectiveness of the proposed methodology for structured generative inference.

TBA        </td></tr>
    </tbody></table>
    <table>
        <tbody><tr>
            <td class="date" rowspan="2">
                10:30am
            </td>
            <td class="title-special">
                Coffee Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </tbody></table>


    <table id="Junwei Lu">
        <tbody><tr>
            <td class="date" rowspan="3">
                11:00am
            </td>
            <td class="title">
                Knowledge Graph Embedding with Electronic Health Records
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://junwei-lu.github.io/"><b>Junwei Lu</b></a> (Harvard)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Due to the increasing adoption of electronic health records (EHR), large EHRs have become another rich data source for translational clinical research. We propose to infer the conditional dependency structure among EHR features via a latent graphical block model. The LGBM has a two-layer structure with the first providing semantic embedding vector  representation for the EHR features and the second overlaying a graphical block model on the latent SEVs. The block structures on the graphical model also allow us to cluster synonymous features in EHR. We propose to learn the LGBM efficiently, in both statistical and computational sense, based on the empirical point mutual information matrix. We establish the statistical rates of the proposed estimators and show the perfect recovery of the block structure. 
        </td></tr>
    </tbody></table>

    <table id="Qiang Sun">
        <tbody><tr>
            <td class="date" rowspan="3">
                11:30am
            </td>
            <td class="title">
                Making Algorithms Robust to Structured Noise, and Beyond
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/qiang-sun/"><b>Qiang Sun</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Real-world data often conceal meaningful signals beneath both random and structured noise. Structured noise arises in many forms, from batch effects in biomedical studies to background in image classification. Surprisingly, algorithms that encourage diversity or uniformity in their learned representations often generalize better out of context. To understand this phenomenon, we study linear representation learning with two views, comparing classical and contrastive methods, with and without a uniformity constraint. The classical non-contrastive algorithms break down under structured noise. Contrastive learning with an alignment-only loss performs well when background variation is mild but fails under strong structured noise. In contrast, contrastive learning that enforces a uniformity constraint remains robust regardless of noise strength. Empirical results confirm these insights. Taking one step further, we discuss how to make algorithms that are robust to random noise and to nonstationary dynamics, such as shifting market trends in algorithmic trading.
        </td></tr>
    </tbody></table>
 
    <table>
        <tbody><tr>
            <td class="date" rowspan="2">
                12:00pm
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </tbody></table>
    <table id="Eran Segal">
        <tbody><tr>
            <td class="date" rowspan="3">
                2:00pm
            </td>
            <td class="title">
            Personalized medicine based on deep human phenotyping
          </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/eran_segal/"><b>Eran Segal</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Recent technological advances allow large cohorts of human individuals to be profiled, presenting many challenges and opportunities. I will present The Human Phenotype Project, a large-scale  (>25,000 participants) deep-phenotype prospective longitudinal cohort and biobank that we established, aimed at identifying novel molecular markers with diagnostic, prognostic and therapeutic value, and at developing prediction models for disease onset and progression. Our deep profiling includes medical history, lifestyle and nutritional habits, vital signs, anthropometrics, blood tests, continuous glucose and sleep monitoring, and molecular profiling of the transcriptome, genetics, gut and oral microbiome, metabolome and immune system. Our analyses of this data provide novel insights into potential drivers of obesity, diabetes, and heart disease, and identify hundreds of novel markers at the microbiome, metabolite, and immune system level. Foundation AI models that we developed provide novel representations of the diverse modalities that we measured on the cohort and achieve state-of-the-art performance in predicting future onset of disease and trajectories of disease risk factors. Overall, our predictive models can be translated into personalized disease prevention and treatment plans, and to the development of new therapeutic modalities based on metabolites and the microbiome.
        </td></tr>
    </tbody></table>
    <table id="Preslav Nakov">
        <tbody><tr>
            <td class="date" rowspan="3">
                2:30pm
            </td>
            <td class="title">
                Towards Truly Open, Language-Specific, Safe, Factual, and Specialized Large Language Models
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/preslav-nakov/"><b>Preslav Nakov</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
As large language models increasingly shape knowledge, communication, and creativity, it is imperative that we make them open, language-specific, safe, factual, and specialized. First, we will argue for the need for fully transparent open-source large language models (LLMs), and we will describe the efforts of MBZUAI's Institute on Foundation Models (IFM) towards that based on the LLM360 initiative. Second, we will argue for the need for language-specific LLMs, and we will share our experience from building Jais, the world's leading open Arabic-centric foundation and instruction-tuned large language model, Nanda, our open-weights Hindi LLM, Sherkala, our open-weights Kazakh LLM, and some other models. Third, we will argue for the need for safe LLMs, and we will present Do-Not-Answer, a dataset for evaluating the guardrails of LLMs, which is at the core of the safety mechanisms of our LLMs. Forth, we will argue for the need for factual LLMs, we will discuss the factuality challenges that LLMs pose. We will then present some recent relevant tools for addressing these challenges developed at MBZUAI: (i) OpenFactCheck, a framework for fact-checking LLM output, for building customized fact-checking systems, and for benchmarking LLMs for factuality, (ii) LM-Polygraph, a tool for predicting an LLM's uncertainty in its output using cheap and fast uncertainty quantification techniques, and (iii) LLM-DetectAIve, a tool for machine-generated text detection. Finally, we will argue for the need for specialized models, and we will present some other LLMs currently being developed at MBZUAI's IFM.
        </td></tr>
    </tbody></table>
    
   
     
    <table>
        <tbody><tr>
            <td class="date" rowspan="2">
                3:00pm
            </td>
            <td class="title-special">
                Coffee Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </tbody></table>

    <table>
        <tbody><tr>
            <td class="date" rowspan="2">
                3:30pm-5:30pm
            </td>
            <td class="title-special">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </tbody></table>
    <table id="Timothy Baldwin">
        <tbody><tr class="speaker">
            <td class="date" rowspan="3">
                5:30 pm
            </td>
            <td class="title-special">
                Closing remarks
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/timothy-baldwin/"><b>Timothy Baldwin</b></a> (MBZUAI)
            </td>
        </tr>
    </tbody></table>


    <!-- <table id="Danqi Chen">
        <tbody><tr>
            <td class="date" rowspan="3">
                9:30am
            </td>
            <td class="title">
                To be determined.
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://www.cs.princeton.edu/~danqic/"><b>Danqi Chen</b></a> (Princeton University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                To be determined.
        </td></tr>
    </tbody></table>

    <table id="Samuel Horvath">
        <tbody><tr>
            <td class="date" rowspan="3">
             9:50am
            </td>
            <td class="title">
                To be determined.
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://samuelhorvath.github.io/"><b>Samuel Horvath</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                To be determined.
        </td></tr>
    </tbody></table>

    <table id="Salman Khan">
        <tbody><tr>
            <td class="date" rowspan="3">
                10:10am
            </td>
            <td class="title">
                To be determined.
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://salman-h-khan.github.io/"><b>Salman Khan</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                To be determined.
        </td></tr>
    </tbody></table>



    <table id="Preslav Nakov">
        <tbody><tr>
            <td class="date" rowspan="3">
                11:00am
            </td>
            <td class="title">
                Factuality Challenges in the Era of Large Language Models: Can We Keep LLMs Safe and Factual?
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/preslav-nakov/"><b>Preslav Nakov</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                We will discuss the risks, the challenges, and the opportunities that Large Language Models (LLMs) bring regarding factuality. We will then present a number of LLM fact-checking tools recently developed at MBZUAI: (i) Factcheck-Bench, a fine-grained evaluation benchmark and framework for fact-checking the output of LLMs, (ii) OpenFactVerification (Loki), an open-source tool for fact-checking the output of LLMs, developed based on Factcheck-Bench and optimized for speed and quality, (iii) OpenFactCheck, a framework for building customized fact-checking systems and for benchmarking entire LLMs, and (iv) LM-Polygraph, a tool to predict an LLM's uncertainty in its output using cheap and fast uncertainty quantification techniques. Finally, we will discuss the safety mechanisms we incorporated in Jais-chat, the world's best open Arabic-centric foundation and instruction-tuned LLM.
        </td></tr>
    </tbody></table>

    <table id="Karthik Nandakumar">
        <tbody><tr>
            <td class="date" rowspan="3">
                11:20am
            </td>
            <td class="title">
                To be determined.
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://www.sprintai.org/nkarthik/"><b>Karthik Nandakumar</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                To be determined.
        </td></tr>
    </tbody></table>

    
    

    <table id="Maxim Panov">
        <tbody><tr>
            <td class="date" rowspan="3">
                11:40am
            </td>
            <td class="title">
                Uncertainty Quantification for Generative Language Models
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/maxim-panov/"><b>Maxim Panov</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The widespread deployment of large language models (LLMs) has made ML-based applications even more vulnerable to risks of causing various forms of harm to users. For example, models often “hallucinate”, i.e., fabricate facts without providing users an apparent means to validate their statements. Uncertainty estimation (UE) methods could be used to detect unreliable generations unlocking the safer and more responsible use of LLMs in practice. UE methods for generative LLMs are a subject of cutting-edge research, which is currently quite scarce and scattered. We systemize these efforts, discuss common caveats, and provide suggestions for the development of novel techniques in this area.
        </td></tr>
    </tbody></table> -->

    

    <!-- <table id="Eric Xing">
        <tbody><tr>
            <td class="date" rowspan="3">
                2pm
            </td>
            <td class="title">
                <font color="red"> (Keynote) </font> Collaborative Learning in Medical Imaging
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://www.nmr.mgh.harvard.edu/user/8165/"><b>Jayashree Kalpathy-Cramer</b></a> (UC Boulder)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Machine learning has shown impressive potential in healthcare, particularly in medical imaging. A lack of access to care in many parts of the globe highlights the need to develop safe and equitable algorithms using diverse datasets.  Despite a surge in research applying deep learning (DL) to problems in healthcare, there remains a gap in its translational impact. Critical hurdles in safely deploying DL algorithms are concerns around brittleness, bias and fairness. The creation of extensive, multi-institutional datasets can enhance model performance and generalizability, but assembling such datasets is challenging due to patient privacy concerns, regulatory hurdles, and financial constraints. Collaborative learning offers a promising way to build more robust models by leveraging diverse datasets without the need to share the data directly. Foundational approaches have also been proposed to address some of these challenges. But challenges remain when dealing with small or heterogenous datasets, as is frequently seen in healthcare.This talk will explore collaborative learning applications in fields such as radiology, oncology, and ophthalmology. We will wrap up with an overview of the practical and theoretical challenges faced in implementing collaborative learning in healthcare contexts.
        </td></tr>
    </tbody></table>

    <table id="Eric Xing">
        <tbody><tr>
            <td class="date" rowspan="3">
                2:30pm
            </td>
            <td class="title">
                <font color="red"> (Keynote) </font> Humanitarian Collaborative Learning
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://www.anniehartley.info/"><b>Mary-Anne Hartley</b></a> (Yale and EPFL)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Humanitarian response aims to reduce preventable deaths and uphold human rights in situations of acute need at scale, such as wars, conflicts, and natural disasters. Organizations such as the International Committee of the Red Cross (ICRC) have been meticulously documenting their interventions in billions of pieces of multimodal data for over a century across 160 countries during countless emergencies. Their data represent the world’s most vulnerable populations and contain invaluable information that could better inform their own responses, as well as broader and longer-term initiatives to reduce inequities, such as the United Nations' Sustainable Development Goals.
 
In practice, however,the data is fragmented across multiple humanitarian actors who do not have the capacity to analyze, harmonize, or anonymize it, and ultimately, this precious information is rarely used beyond basic internal reporting in Excel sheets. 

In this talk, I will share my experience of collaborating with several NGOs to make data-driven tools for humanitarian interventions. I will make a semantic mapping of the seven cardinal humanitarian principles (neutrality, impartiality, independence, humanity, voluntary service, unity, universality) with distributed learning and also highlight methodological approaches that could integrate humanitarian principles into the design of these tools to better ensure real-world adoption.
        </td></tr>
    </tbody></table> -->



  <!--   <table>
        <tbody><tr>
            <td class="date" rowspan="2">
                3:00pm
            </td>
            <td class="title-special">
                Panel Discussion and Coffee
            </td>
        </tr>
        <tr>
        </tr>
    </tbody></table> -->


    

    

    


</body></html>