<!DOCTYPE html>
<!-- saved from url=(0045)https://mbzuai-cl.github.io/2023/programday1/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!--<base href=".">--><base href=".">
    <link rel="shortcut icon" type="image/png" href="https://mbzuai-cl.github.io/2023/assets/favicon.png">
    <link rel="stylesheet" type="text/css" media="all" href="./MLLM2024_day1_files/main.css">
    <meta name="description" content="MBZUAI Machine Learning for Large Models Workshop 2024">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>MBZUAI Workshop on Data, Learning, and Biological Problems</title>
</head>

<body>

    <div class="banner">
        <img src="./MLLM2024_files/banner.jpeg" alt="MBZUAI Machine Learning for Large Models 2024 Banner">
        <div class="top-left">
            <span class="title2">MBZUAI Workshop on </span>
            <br><br> <span class="title1" style="font-size: 38px;">Data, Learning, and Biological Problems</span> 
            <!-- <br><br>
            <span class="year">Empowering Sustainable Futures</span> -->
        </div>
        <div class="bottom-right">
            Nov 10-11, 2025 <br> MBZUAI, Abu Dhabi
        </div>
    </div>

    <table class="navigation">
        <tbody><tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href="index.html">Home</a>
            </td>
           <!-- <td class="navigation">
                <a title="Speakers List" href="speakerlist.html">Program Day 1</a> 
            </td> -->
            <td class="navigation">
                <a title="Conference Program" href="day1.html">Program Day 1</a> 
            </td>
            <!-- <td class="navigation">
                <a title="Conference Program" href="https://mbzuai.ac.ae/">MBZUAI</a> 
            </td> -->
            <td class="navigation">
                <a title="Conference Program Day 2" href="day2.html">Program Day 2</a> 
            </td>
        </tr>
    </tbody></table>

   

    <h2>Program (November 10, Monday)</h2>

    <table id="Eric Xing">
        <tbody><tr class="speaker">
            <td class="date" rowspan="3">
                9:10 am
            </td>
            <td class="title-special">
                Welcome and Opening remarks
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/professor-eric-xing/"><b>Eric Xing</b></a> (MBZUAI)
            </td>
        </tr>
    </tbody></table>

    <table id="Tianxi Cai">
        <tbody><tr>
            <td class="date" rowspan="3">
                9:30 am
            </td>
            <td class="title">
                
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://dbmi.hms.harvard.edu/people/tianxi-cai"><b>Tianxi Cai</b></a> (Harvard)
            </td>
        </tr>
    </tbody></table>

    <table id="Kun Zhang">
        <tbody><tr>
            <td class="date" rowspan="3">
                10:00 am
            </td>
            <td class="title">
                Causal representation learning and causal generative AI
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/kun-zhang/"><b>Kun Zhang</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Causality is a fundamental notion in science, engineering, and even in machine learning. Uncovering the causal process behind observed data can naturally help answer 'why' and 'how' questions, inform optimal decisions, and achieve adaptive prediction. In many scenarios, observed variables (such as image pixels and questionnaire results) are often reflections of the underlying causal variables, instead of causal variables themselves. Causal representation learning aims to reveal the underlying hidden causal variables and their relations. In this talk, we show how the modularity property of causal systems makes it possible to recover the underlying causal representations from observational data with identifiability guarantees: under appropriate assumptions, the learned representations are consistent with the underlying causal process. We demonstrate how identifiable causal representation learning can naturally benefit generative AI, with image generation, image editing, and text generation as particular examples.
        </td></tr>
    </tbody></table>

      <table>
        <tbody><tr>
            <td class="date" rowspan="2">
                10:30am
            </td>
            <td class="title-special">
                Coffee Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </tbody></table>
    
     <table id="Jin Tian">
        <tbody><tr>
            <td class="date" rowspan="3">
                11:00am
            </td>
            <td class="title">
                Causal Effect Measures Beyond the Mean
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/jin-tian/"><b>Jin Tian</b></a> (MBZUAI)
            </td>
        </tr>
       <tr>
            <td class="abstract">
                Causal effect measures are fundamental to understanding interventions and play key roles in causal explanation, decision-making, and responsibility attribution. Traditional measures, such as the Average Causal Effect (ACE), summarize causal relationships through averages but often obscure important heterogeneity in effects across individuals or subpopulations. In this talk, we introduce a set of new causal effect measures designed to capture and interpret causal heterogeneity. After reviewing standard measures and the Probabilities of Causation framework, we introduce new metrics that extend these ideas to continuous treatments and outcomes, propose characterizing the distribution of causal effects through its moments (variance, skewness, kurtosis), and present new measures for decision-making under multiple actions. Finally, we outline identification and bounding results for these measures under common causal assumptions, and illustrate their use in real-world applications.
        </td></tr>
    </tbody></table>

   

 <table id="Yihong Gu">
        <tbody><tr>
            <td class="date" rowspan="3">
                11:30am
            </td>
            <td class="title">
                Invariance and causality pursuit from heterogeneous environments
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://sites.google.com/view/yihongg/home"><b>Yihong Gu</b></a> (Harvard)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            Pursuing causality from data is a fundamental problem in scientific discovery, treatment intervention, and transfer learning. In this talk, we introduce a novel algorithmic method for addressing nonparametric invariance and causality learning in regression models across multiple environments, where the joint distribution of response variables and covariates varies, but the conditional expectations of outcome given an unknown set of quasi-causal variables are invariant. The challenge of finding such an unknown set of quasi-causal or invariant variables is compounded by the presence of endogenous variables that have heterogeneous effects across different environments. The proposed Focused Adversarial Invariant Regularization (FAIR) framework utilizes an innovative minimax optimization approach that drives regression models toward prediction-invariant solutions through adversarial testing. Leveraging the representation power of neural networks, FAIR neural networks (FAIR-NN) are introduced for causality pursuit. It is shown that FAIR-NN can find the invariant variables and quasi-causal variables under a minimal identification condition and that the resulting procedure is adaptive to low-dimensional composition structures in a non-asymptotic analysis. Under a structural causal model, variables identified by FAIR-NN represent pragmatic causality and provably align with exact causal mechanisms under conditions of sufficient heterogeneity. Computationally, FAIR-NN employs a novel Gumbel approximation with decreased temperature and a stochastic gradient descent ascent algorithm. Finally, we also discuss the intrinsic computational hardness in theory.      </td></tr>
    </tbody></table>

    <table id="Yulia Medvedeva">
        <tbody><tr>
            <td class="date" rowspan="3">
                12:00am
            </td>
            <td class="title">
                TBA
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/yulia-medvedeva/"><b>Yulia Medvedeva</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
TBA        </td></tr>
    </tbody></table>
   

   <table>
        <tbody><tr>
            <td class="date" rowspan="2">
                12:30pm
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </tbody></table>

    <table id="Natasa Przulj">
        <tbody><tr>
            <td class="date" rowspan="3">
                2:00pm
            </td>
            <td class="title">
            Predictive Patient Analytics and Precision Therapeutics from Multi-Omics Data
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/natasa-przulj/"><b>Natasa Przulj</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Large amounts of multi-omic data are increasingly becoming available. They provide complementary information about cells, tissues and diseases. We need to utilize them to better stratify patients into risk groups, discover new biomarkers and targets, re-purpose known and discover new drugs to personalize medical treatment. This is nontrivial, because of computational intractability of many underlying problems on large interconnected data (networks, or graphs), necessitating the development of new algorithms for finding approximate solutions (heuristics).

We develop versatile artificial intelligence (AI) frameworks for multi-omics data fusion, constrained by the state-of-the-art network science methods, to address key challenges in precision medicine and pharmacology from time-series, multi-omics data, including patient-derived single-cell data, to: better stratify patients, predict new biomarkers and targets, re-purpose existing and discover new drugs; we apply these to different types of cancer, Covid-19, Parkinson’s and other diseases. Our new methods stem from graph-regularized non-negative matrix tri-factorization (NMTF), a machine learning (ML) technique for dimensionality reduction, inference, fusion and co-clustering of heterogeneous datasets, coupled with novel graphlet-based network science algorithms. We utilize our new frameworks for improving the understanding of the molecular organization of life and of diseases from the embedding spaces of omics data. Also, we utilize the local network topology to correct for the topological information missed by random walks used in many ML methods, and to enable embedding of multi-omics networks into more linearly separable spaces, allowing for their explainable and sustainable mining. The aim is to develop an overreaching framework encompassing all multi-omics data towards consumer-facing precision medicine products.

        </td></tr>
    </tbody></table>
    
    <table id="Xihong Lin">
        <tbody><tr>
            <td class="date" rowspan="3">
                2:30pm
            </td>
            <td class="title">
                TBA
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://hsph.harvard.edu/profile/xihong-lin/"><b>Xihong Lin</b></a> (Harvard)
            </td>
        </tr>
       <!--  <tr>
            <td class="abstract">
                Large Language Models (LLMs) can be misused to spread online spam and misinformation. Content watermarking deters misuse by hiding a message in model-generated outputs, enabling their detection using a secret watermarking key. Robustness is a core security property, stating that evading detection requires (significant) degradation of the content’s quality. Many LLM watermarking methods have been proposed, but robustness is tested only against non-adaptive attackers who lack knowledge of the watermarking method and can find only suboptimal attacks. We formulate the robustness of LLM watermarking as an objective function and propose preference-based optimization to tune adaptive attacks against the specific watermarking method. Our evaluation shows that (i) adaptive attacks substantially outperform non-adaptive baselines. (ii) Even in a non-adaptive setting, adaptive attacks optimized against a few known watermarks remain highly effective when tested against other unseen watermarks and (iii) optimization-based attacks are practical and require less than seven GPU hours. Our findings underscore the need to test robustness against adaptive attackers.
        </td></tr> -->
    </tbody></table>

    
    <table id="Le Song">
        <tbody><tr>
            <td class="date" rowspan="3">
                3:00pm
            </td>
            <td class="title">
                TBA
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/professor-le-song/"><b>Le Song</b></a> (MBZUAI)
            </td>
        </tr>
        <!-- <tr>
            <td class="abstract">
                Machine learning methods—particularly graph neural networks (GNNs)—have emerged as powerful tools for accelerating the search for novel catalytic materials. By representing each material as a graph where atoms are nodes and bonds are edges, GNNs can capture local atomic interactions while still scaling to realistic systems. However, designing a GNN architecture that both assimilates global context and respects essential physical symmetries is nontrivial.
                In this talk, we provide an overview of GNNs for materials discovery and explain how deeper message-passing architectures can improve expressiveness yet risk “over-smoothing”—a phenomenon where atom-level embeddings become indistinguishable. We then highlight PaiNN as one promising approach that ensures rotational and translational equivariance. By incorporating these symmetries directly into the model, PaiNN preserves physically meaningful geometric information and yields more robust and interpretable predictions.
                Finally, we focus on predicting the Density of States (DOS), a property that reveals the distribution of electronic states and is crucial for identifying active sites in catalytic reactions. Accurate DOS predictions help pinpoint where electrons can be exchanged during catalysis, guiding experimental efforts toward more efficient and sustainable catalysts. Through concrete examples, we illustrate how GNN-based DOS modeling can bridge the gap between quantum-mechanical theory and large-scale materials discovery.
        </td></tr> -->
    </tbody></table>

<table>
        <tbody><tr>
            <td class="date" rowspan="3">
                3:30pm
            </td>
            <td class="title-special">
                Coffee Break
            </td>
        </tr>
 
        <!-- <tr> -->
           <!--  <td class="abstract">
                TBA
        </td></tr> -->
    </tbody></table>

   <table id="Rong Ma">
        <tbody><tr>
            <td class="date" rowspan="3">
                4:00pm
            </td>
            <td class="title">
                Modern Nonlinear Embedding Methods Unpacked: Empowering Biological Discoveries with Statistical Insights
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://sites.google.com/site/rongmastat/home"><b>Rong Ma</b></a> (Harvard)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Learning and representing low-dimensional structures from noisy, high-dimensional data is a cornerstone of modern biomedical data science. Stochastic neighbor embedding algorithms, a family of nonlinear dimensionality reduction and data visualization methods, with t-SNE and UMAP as two leading examples, have become especially influential in recent years, particularly in single-cell analysis. Yet despite their popularity, these methods remain subject to points of debate, including limited theoretical understanding, ambiguous interpretations, and sensitivity to tuning parameters. In this talk, I will present our recent efforts to decipher and improve these nonlinear embedding approaches. Our key results include a rigorous theoretical framework that uncovers the intrinsic mechanisms, large-sample limits, and fundamental principles underlying these algorithms; a set of theory-informed practical guidelines for their principled use in trustworthy biological discovery; and a collection of new algorithms that address current limitations and improve performance in areas such as bias reduction and stability. Throughout the talk, I will highlight how these advances not only deepen our statistical understanding but also open new avenues for biological insight.
        </td></tr>
    </tbody></table>

    <table id="Salman Khan">
        <tbody><tr>
            <td class="date" rowspan="3">
                4:30pm
            </td>
            <td class="title">
                TBA
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://mbzuai.ac.ae/study/faculty/salman-khan/"><b>Salman Khan</b></a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                TBA
            </td></tr>
    </tbody></table>
    
    <table id="Ahmad Abdel-Azim">
        <tbody><tr>
            <td class="date" rowspan="3">
                5:00pm
            </td>
            <td class="title">
                Robustifying Generative AI for Human Genetics
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="https://ahmadabdel-azim.com/"><b>Ahmad Abdel-Azim</b></a> (Harvard)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Generative AI has transformed content generation, and its promise for biomedicine is compelling. Genomic sequencing remains costly and scarce relative to phenotyping, and privacy restrictions further limit access. We introduce a scalable pipeline for the generation of high-fidelity genomes, building on the latent diffusion model architecture (e.g. Stable Diffusion). Genotypes are efficiently embedded in a regularized, informative latent space where a conditional diffusion model is subsequently trained; this enables the generation of high-fidelity genetic data, where fidelity is assessed with genomics-specific diagnostics. Practically, sampling from the learned genomic distribution provides “data on demand"; millions of high-fidelity genomes can be generated to power variant discovery, fine-mapping, and other analyses, hence facilitating more rapid discovery. Nevertheless, the challenge is not only the generative modeling of genomes, but how to use the generated data without corrupting downstream inference procedures and inducing bias. We introduce a synthetic augmentation framework that is robust to misspecification of the data generative models. Our proposed framework is guaranteed to be more efficient than standard estimation procedures based solely on the observed data, even when the generators are imperfect. Applied in simulations and the UK Biobank, the approach delivers higher-powered genetic analyses. More broadly, we establish a general framework for robust inference with generative modeling, extensible to other modalities, which can accelerate discovery while reducing data-collection costs and privacy risks.
        </td></tr>
    </tbody></table>

    
</body></html>